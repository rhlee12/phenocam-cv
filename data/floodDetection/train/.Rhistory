img_matrix <- grayimg@.Data
## Coerce to a vector (row-wise)
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if(labelsExist){
return(list(X = feature_matrix, y = y))
}else{
return(feature_matrix)
}
}
# Set image size
width<-50
height<-50
library(pbapply)
extract_feature <- function(dir_path, width, height, is_cat = TRUE, add_label = TRUE) {
img_size <- width*height
## List images in path
images_names <- list.files(dir_path)
if (add_label) {
## Select only cats or dogs images
images_names <- images_names[grepl(ifelse(is_cat, "cat", "dog"), images_names)]
## Set label, cat = 0, dog = 1
label <- ifelse(is_cat, 0, 1)
}
#browser()
#only grab 1000 images:
#grab only first 1000 images of each
images_names<-images_names[1:1000]
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- imager::load.image(file.path(dir_path, imgname))
## Resize image
img_resized <- imager::resize(img, size_x = width, size_y =  height)
## Set to grayscale
grayimg <- imager::grayscale(img_resized)
## Get the image as a matrix
img_matrix <- as.matrix(grayimg)
#grayimg@.Data
## Coerce to a vector
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if (add_label) {
## Add label
feature_matrix <- cbind(label = label, feature_matrix)
}
return(feature_matrix)
}
width<-50
height<-50
library(pbapply)
extract_feature <- function(dir_path, width, height, is_cat = TRUE, add_label = TRUE) {
img_size <- width*height
## List images in path
images_names <- list.files(dir_path)
if (add_label) {
## Select only cats or dogs images
images_names <- images_names[grepl(ifelse(is_cat, "cat", "dog"), images_names)]
## Set label, cat = 0, dog = 1
label <- ifelse(is_cat, 0, 1)
}
#browser()
#only grab 1000 images:
#grab only first 1000 images of each
images_names<-images_names[1:1000]
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- imager::load.image(file.path(dir_path, imgname))
## Resize image
img_resized <- imager::resize(img, size_x = width, size_y =  height)
## Set to grayscale
grayimg <- imager::grayscale(img_resized)
## Get the image as a matrix
img_matrix <- as.matrix(grayimg)
#grayimg@.Data
## Coerce to a vector
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if (add_label) {
## Add label
feature_matrix <- cbind(label = label, feature_matrix)
}
return(feature_matrix)
}
cats_data <- extract_feature(dir_path = imageDir, width = width, height = height)
dogs_data <-extract_feature(dir_path = imageDir, width = width, height = height,is_cat = F)
#set image directory:
imageDir<-"C:/Users/jroberti/Kaggle/imgClassification/train/"
# Set image size
width<-50
height<-50
library(pbapply)
extract_feature <- function(dir_path, width, height, is_cat = TRUE, add_label = TRUE) {
img_size <- width*height
## List images in path
images_names <- list.files(dir_path)
if (add_label) {
## Select only cats or dogs images
images_names <- images_names[grepl(ifelse(is_cat, "cat", "dog"), images_names)]
## Set label, cat = 0, dog = 1
label <- ifelse(is_cat, 0, 1)
}
#browser()
#only grab 1000 images:
#grab only first 1000 images of each
images_names<-images_names[1:1000]
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- imager::load.image(file.path(dir_path, imgname))
## Resize image
img_resized <- imager::resize(img, size_x = width, size_y =  height)
## Set to grayscale
grayimg <- imager::grayscale(img_resized)
## Get the image as a matrix
img_matrix <- as.matrix(grayimg)
#grayimg@.Data
## Coerce to a vector
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if (add_label) {
## Add label
feature_matrix <- cbind(label = label, feature_matrix)
}
return(feature_matrix)
}
cats_data <- extract_feature(dir_path = imageDir, width = width, height = height)
dogs_data <-extract_feature(dir_path = imageDir, width = width, height = height,is_cat = F)
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
## 3 Train the Model
library(caret)
## Bind rows in a single dataset
complete_set <- rbind(cats_data, dogs_data)
## test/training partitions
training_index <- createDataPartition(complete_set$label, p = .9, times = 1)
training_index <- unlist(training_index)
train_set <- complete_set[training_index,]
dim(train_set)
#create the test set:
test_set <- complete_set[-training_index,]
dim(test_set)
## Fix train and test datasets
train_data <- data.matrix(train_set)
train_x <- t(train_data[, -1])
train_y <- train_data[,1]
train_array <- train_x
dim(train_array) <- c(40, 40, 1, ncol(train_x))
test_data <- data.matrix(test_set)
test_x <- t(test_set[,-1])
test_y <- test_set[,1]
test_array <- test_x
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
library(keras)
install.packages("keras")
library(keras)
library(EBImage)
library(stringr)
library(pbapply)
## 3 Train the Model
library(caret)
## Bind rows in a single dataset
complete_set <- rbind(cats_data, dogs_data)
## test/training partitions
training_index <- createDataPartition(complete_set$label, p = .9, times = 1)
training_index <- unlist(training_index)
train_set <- complete_set[training_index,]
dim(train_set)
#create the test set:
test_set <- complete_set[-training_index,]
dim(test_set)
## Fix train and test datasets
train_data <- data.matrix(train_set)
train_x <- t(train_data[, -1])
train_y <- train_data[,1]
train_array <- train_x
test_data <- data.matrix(test_set)
test_x <- t(test_set[,-1])
test_y <- test_set[,1]
test_array <- test_x
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
Y
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
install_tensorflow()
keras::install_keras()
keras::install_tensorFlow()
install_tensorFlow()
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/tensorflow")
install.packages("jsonlite")
install.packages("jsonlite")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
tensorflow::install_tensorflow()
tensorflow::tf_config()
library(keras)
library(EBImage)
library(stringr)
library(pbapply)
#set image directory:
imageDir<-"C:/Users/jroberti/Kaggle/imgClassification/train/"
# Set image size
width<-50
height<-50
library(pbapply)
extract_feature <- function(dir_path, width, height, is_cat = TRUE, add_label = TRUE) {
img_size <- width*height
## List images in path
images_names <- list.files(dir_path)
if (add_label) {
## Select only cats or dogs images
images_names <- images_names[grepl(ifelse(is_cat, "cat", "dog"), images_names)]
## Set label, cat = 0, dog = 1
label <- ifelse(is_cat, 0, 1)
}
#browser()
#only grab 1000 images:
#grab only first 1000 images of each
images_names<-images_names[1:1000]
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- imager::load.image(file.path(dir_path, imgname))
## Resize image
img_resized <- imager::resize(img, size_x = width, size_y =  height)
## Set to grayscale
grayimg <- imager::grayscale(img_resized)
## Get the image as a matrix
img_matrix <- as.matrix(grayimg)
#grayimg@.Data
## Coerce to a vector
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if (add_label) {
## Add label
feature_matrix <- cbind(label = label, feature_matrix)
}
return(feature_matrix)
}
cats_data <- extract_feature(dir_path = imageDir, width = width, height = height)
dogs_data <-extract_feature(dir_path = imageDir, width = width, height = height,is_cat = F)
## 3 Train the Model
library(caret)
## Bind rows in a single dataset
complete_set <- rbind(cats_data, dogs_data)
## test/training partitions
training_index <- createDataPartition(complete_set$label, p = .9, times = 1)
training_index <- unlist(training_index)
train_set <- complete_set[training_index,]
dim(train_set)
#create the test set:
test_set <- complete_set[-training_index,]
dim(test_set)
## Fix train and test datasets
train_data <- data.matrix(train_set)
train_x <- t(train_data[, -1])
train_y <- train_data[,1]
train_array <- train_x
#dim(train_array) <- c(40, 40, 1, ncol(train_x))
test_data <- data.matrix(test_set)
test_x <- t(test_set[,-1])
test_y <- test_set[,1]
test_array <- test_x
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
summary(model)
tensorflow::install_tensorflow()
tensorflow::tf_config()
reticulate::py_discover_config()
reticulate::use_condaenv("r-tensorflow")
reticulate::py_config()
tensorflow::tf_config()
tensorflow::install_tensorflow()
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
install_tensorflow()
tensorflow::install_tensorflow()
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %>%
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
#flatten the images:
# Fix structure for 2d CNN
# Fix structure for 2d CNN
train_array %
train_array %
layer_dropout(rate = 0.25) %>%
layer_flatten() %>%
layer_dense(units = 50, activation = "relu") %>%
layer_dropout(rate = 0.25) %>%
layer_dense(units = 1, activation = "sigmoid")
summary(model)
## Example of image classifications from https://rstudio-pubs-static.s3.amazonaws.com/236125_e0423e340e4b437888423d3821626d92.html
# install.packages("drat", repos="https://cran.rstudio.com")
# drat:::addRepo("dmlc")
#install.packages("https://s3.ca-central-1.amazonaws.com/jeremiedb/share/mxnet/CPU/mxnet.zip", repos = NULL)
#set seed for traceability:
set.seed(2020)
#set image directory:
imageDir<-"C:/Users/jroberti/Kaggle/imgClassification/train/"
#open one of the images in the training set:
library(imager)
img.exampleCat<-imager::load.image(paste0(imageDir,"/cat.0.jpg"))
plot(img.exampleCat)
img.exampleDog<-imager::load.image(paste0(imageDir,"/dog.0.jpg"))
plot(img.exampleDog)
## 2 Data Preprocessing
### Convert the images to dims of 40 x 40 and turn into greyscale:
width <- 40
height <- 40
## pbapply is a library to add progress bar *apply functions
## pblapply will replace lapply
library(pbapply)
extract_feature <- function(dir_path, width, height, is_cat = TRUE, add_label = TRUE) {
img_size <- width*height
## List images in path
images_names <- list.files(dir_path)
if (add_label) {
## Select only cats or dogs images
images_names <- images_names[grepl(ifelse(is_cat, "cat", "dog"), images_names)]
## Set label, cat = 0, dog = 1
label <- ifelse(is_cat, 0, 1)
}
#browser()
#only grab 1000 images:
#grab only first 1000 images of each
images_names<-images_names#[1:1000]
print(paste("Start processing", length(images_names), "images"))
## This function will resize an image, turn it into greyscale
feature_list <- pblapply(images_names, function(imgname) {
## Read image
img <- imager::load.image(file.path(dir_path, imgname))
## Resize image
img_resized <- imager::resize(img, size_x = width, size_y =  height)
## Set to grayscale
grayimg <- imager::grayscale(img_resized)
## Get the image as a matrix
img_matrix <- as.matrix(grayimg)
#grayimg@.Data
## Coerce to a vector
img_vector <- as.vector(t(img_matrix))
return(img_vector)
})
## bind the list of vector into matrix
feature_matrix <- do.call(rbind, feature_list)
feature_matrix <- as.data.frame(feature_matrix)
## Set names
names(feature_matrix) <- paste0("pixel", c(1:img_size))
if (add_label) {
## Add label
feature_matrix <- cbind(label = label, feature_matrix)
}
return(feature_matrix)
}
#width<-40
#height<-40
#image_dir<-"~/Github/L0-tracking/scratch/imgs/imgClassification/train/"
#apply above function to the cats data and the dogs data:
cats_data <- extract_feature(dir_path = imageDir, width = width, height = height)
dogs_data <-extract_feature(dir_path = imageDir, width = width, height = height,is_cat = F)
#save the data as .rds just in case:
saveRDS(cats_data, "C:/Users/jroberti/Kaggle/imgClassification/cat.rds")
saveRDS(dogs_data, "C:/Users/jroberti/Kaggle/imgClassification/dog.rds")
install.packages("tensorflow")
install.packages("tensorflow")
install.packages("Rtools")
library(tensorflow)
install_tensorflow()
library(tensorflow)
tf$constant("Hellow Tensorflow")
library(tensorflow)
install_tensorflow()
library(tensorflow)
install_tensorflow(version = "https://files.pythonhosted.org/packages/c2/c1/a035e377cf5a5b90eff27f096448fa5c5a90cbcf13b7eb0673df888f2c2d/tf_nightly-1.12.0.dev20180918-cp36-cp36m-manylinux1_x86_64.whl")
install_tensorflow()
library(tensorflow)
tensorflow::install_tensorflow()
tensorflow::tf_config()
library(tensorflow)
sess= tf$Session()
install_tensorflow()
keras::install_keras()
if (FALSE) {
# default installation
library(keras)
install_keras()
# install using a conda environment (default is virtualenv)
install_keras(method = "conda")
# install with GPU version of TensorFlow
# (NOTE: only do this if you have an NVIDIA GPU + CUDA!)
install_keras(tensorflow = "gpu")
# install a specific version of TensorFlow
install_keras(tensorflow = "1.2.1")
install_keras(tensorflow = "1.2.1-gpu")
}
if (FALSE) {
# default installation
library(keras)
install_keras()
# install using a conda environment (default is virtualenv)
install_keras(method = "conda")
# install with GPU version of TensorFlow
# (NOTE: only do this if you have an NVIDIA GPU + CUDA!)
install_keras(tensorflow = "gpu")
# install a specific version of TensorFlow
install_keras(tensorflow = "1.2.1")
install_keras(tensorflow = "1.2.1-gpu")
}
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
install.rtools()
install.packages("installr")
install.rtools()
installr::install.rtools()
installr::install.rtools()
installr::install.Rtools()
installr::install.Rtool
installr::install.Rtools()
